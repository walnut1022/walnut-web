import os
import shutil
import subprocess
import math
import uuid
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from dotenv import load_dotenv  # ğŸ‘ˆ ì´ ì„í¬íŠ¸ê°€ ë¹ ì ¸ìˆì–´ì„œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤
from openai import OpenAI
from anthropic import Anthropic 

print("================ ì ê²€ ì‹œì‘ ================")
openai_key = os.environ.get("OPENAI_API_KEY")
claude_key = os.environ.get("ANTHROPIC_API_KEY")

print(f"1. OpenAI í‚¤ ìƒíƒœ: {'âœ… ì„±ê³µ' if openai_key else 'âŒ ì‹¤íŒ¨ (None)'}")
if openai_key: print(f"   ã„´ ì•ìë¦¬ í™•ì¸: {openai_key[:5]}...")

print(f"2. Claude í‚¤ ìƒíƒœ: {'âœ… ì„±ê³µ' if claude_key else 'âŒ ì‹¤íŒ¨ (None)'}")
if claude_key: print(f"   ã„´ ì•ìë¦¬ í™•ì¸: {claude_key[:10]}...")
print("================ ì ê²€ ë ================")
# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ ì½ê¸°)
load_dotenv()

app = FastAPI()

# 2. CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ í†µì‹  í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. ì—…ë¡œë“œ í´ë” ìƒì„±
UPLOAD_DIR = "temp_uploads"
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)

# 4. ëª¨ë¸ ì„¤ì • (Claude 3.5 Sonnet)
CLAUDE_MODEL = "claude-3-5-sonnet-20240620"

# íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§· í•¨ìˆ˜
def format_timestamp(seconds):
    hours = math.floor(seconds / 3600)
    seconds %= 3600
    minutes = math.floor(seconds / 60)
    seconds %= 60
    return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{int((seconds % 1) * 1000):03d}"

@app.post("/upload/video")
async def upload_video(file: UploadFile = File(...)):
    try:
        # [ìˆ˜ì •ë¨] í•˜ë“œì½”ë”©ëœ í‚¤ ì‚­ì œí•¨. ë¬´ì¡°ê±´ .envë‚˜ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        openai_api_key = os.environ.get("OPENAI_API_KEY")
        anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")

        if not openai_api_key or not anthropic_api_key:
            raise HTTPException(status_code=500, detail="API Keyê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai_client = OpenAI(api_key=openai_api_key)
        anthropic_client = Anthropic(api_key=anthropic_api_key)

        # [1] íŒŒì¼ ì €ì¥
        file_id = str(uuid.uuid4())
        filename = f"{file_id}.mp4"
        file_path = os.path.join(UPLOAD_DIR, filename)
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        abs_input_path = os.path.abspath(file_path)
        abs_audio_path = os.path.abspath(file_path.replace(".mp4", ".mp3"))
        
        # FFmpegë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
        subprocess.run([
            'ffmpeg', '-y', '-i', abs_input_path, '-vn', '-acodec', 'libmp3lame', abs_audio_path
        ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        # [2] ë“£ê¸° ë‹´ë‹¹: OpenAI Whisper
        print("ğŸ‘‚ 1. OpenAIê°€ ì˜ìƒì„ ë“£ê³  ë°›ì•„ì“°ëŠ” ì¤‘...")
        with open(abs_audio_path, "rb") as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file,
                response_format="verbose_json"
            )

        full_text = transcript.text
        sample_text = full_text[:1000] 

        # [3] ê°ë… ë‹´ë‹¹: Claude (ë¶„ìœ„ê¸° ë¶„ì„)
        print(f"ğŸ§  2. Claude({CLAUDE_MODEL})ê°€ ì˜ìƒ ë¶„ìœ„ê¸°ë¥¼ ì •ë°€ ë¶„ì„í•©ë‹ˆë‹¤...")
        
        director_response = anthropic_client.messages.create(
            model=CLAUDE_MODEL, 
            max_tokens=1000,
            temperature=0, # ë¶„ì„ì€ ì •í™•í•´ì•¼ í•˜ë¯€ë¡œ 0 ì¶”ì²œ
            system="""
            ë„ˆëŠ” ì„¸ê³„ ìµœê³ ì˜ 'ì˜ìƒ ë²ˆì—­ ë””ë ‰í„°'ì•¼. 
            ì£¼ì–´ì§„ ìŠ¤í¬ë¦½íŠ¸ì˜ [ì¥ë¥´, í™”ìì˜ ì„±ê²©, ìƒí™©, íƒ€ê²Ÿ ì‹œì²­ì]ë¥¼ ì™„ë²½í•˜ê²Œ ë¶„ì„í•´.
            ê·¸ë¦¬ê³  ê·¸ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ë²ˆì—­ê°€ê°€ ë”°ë¼ì•¼ í•  'êµ¬ì²´ì ì¸ ë²ˆì—­ ì§€ì¹¨(System Prompt)'ì„ ì‘ì„±í•´ì¤˜.
            
            ê²°ê³¼ëŠ” êµ°ë”ë”ê¸° ì—†ì´ ì˜¤ì§ 'ì§€ì¹¨(System Prompt)' ë‚´ìš©ë§Œ ì¶œë ¥í•´.
            """,
            messages=[
                {"role": "user", "content": f"ë¶„ì„í•  ìŠ¤í¬ë¦½íŠ¸ ìƒ˜í”Œ:\n{sample_text}"}
            ]
        )
        
        # ì‘ë‹µ ì²˜ë¦¬ (text íƒ€ì… í™•ì¸)
        custom_system_prompt = ""
        if director_response.content and director_response.content[0].type == 'text':
             custom_system_prompt = director_response.content[0].text
        else:
             custom_system_prompt = "ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜."

        print(f"ğŸ¯ Claudeì˜ ë¶„ì„ ê²°ê³¼:\n{custom_system_prompt}\n----------------")

        # [4] ë²ˆì—­ ë‹´ë‹¹: Claude (ì‹¤ì „ ë²ˆì—­ - ë£¨í”„)
        srt_content = ""
        print("ğŸ‡°ğŸ‡· 3. Claudeê°€ ê°ì¹ ë§› ë‚˜ê²Œ ë²ˆì—­ ì¤‘...")
        
        segments = transcript.segments
        
        for i, segment in enumerate(segments): 
            start = format_timestamp(segment.start) 
            end = format_timestamp(segment.end)
            text = segment.text

            # Claudeì—ê²Œ ë²ˆì—­ ìš”ì²­
            trans_res = anthropic_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=300,
                temperature=0,
                system=custom_system_prompt, 
                messages=[
                    {"role": "user", "content": f"Translate this subtitle to Korean naturally: {text}"}
                ]
            )
            
            kor_text = trans_res.content[0].text
            srt_content += f"{i+1}\n{start} --> {end}\n{kor_text}\n\n"
            
            # ì§„í–‰ ìƒí™© ë¡œê·¸ (ì„ íƒ ì‚¬í•­)
            print(f"[{i+1}/{len(segments)}] ë²ˆì—­ ì™„ë£Œ")

        # SRT íŒŒì¼ ì €ì¥
        srt_path = os.path.join(UPLOAD_DIR, f"{file_id}.srt")
        with open(srt_path, "w", encoding="utf-8") as f:
            f.write(srt_content)

        # [5] ìë§‰ í•©ì„± (FFmpeg)
        output_video_path = os.path.join(UPLOAD_DIR, f"subtitled_{file_id}.mp4")
        
        # ìœˆë„ìš° ê²½ë¡œ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        # ë“œë¼ì´ë¸Œ ë¬¸ì ë’¤ì˜ ì½œë¡ (:)ì„ ì´ìŠ¤ì¼€ì´í”„í•˜ê³  ì—­ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€ê²½
        abs_srt_path = os.path.abspath(srt_path).replace("\\", "/").replace(":", "\\\\:")
        
        print("ğŸ¬ 4. ìë§‰ í•©ì„± ì¤‘...")
        # í°íŠ¸ ìŠ¤íƒ€ì¼ ì§€ì • (ë§‘ì€ ê³ ë”• ë“± í•œê¸€ í°íŠ¸ ì¶”ì²œ)
        style = "Fontname=Malgun Gothic,Fontsize=20,PrimaryColour=&H00FFFF&,OutlineColour=&H000000&,BorderStyle=1,Outline=1,Shadow=0,MarginV=20"
        
        subprocess.run([
            'ffmpeg', '-y', 
            '-i', abs_input_path, 
            '-vf', f"subtitles='{abs_srt_path}':force_style='{style}'", 
            '-c:a', 'copy', 
            output_video_path
        ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼ ì „ì†¡ ì‹œì‘")
        
        return FileResponse(output_video_path, media_type="video/mp4", filename="walnut_output.mp4")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        # ì—ëŸ¬ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ í´ë¼ì´ì–¸íŠ¸ì— ì „ë‹¬ (ë””ë²„ê¹…ìš©)
        raise HTTPException(status_code=500, detail=str(e))