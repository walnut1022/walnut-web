import os
from pathlib import Path
from fastapi import FastAPI, UploadFile, File, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from dotenv import load_dotenv
import google.generativeai as genai
from openai import OpenAI
import math
import uuid
import shutil
import subprocess
import json
import asyncio
import re

# ========================================================
# ê¸°ë³¸ ì„¤ì •
# ========================================================
current_dir = Path(__file__).resolve().parent
env_path = current_dir / ".env"
upload_dir = current_dir / "tempuploads"

if env_path.exists():
    load_dotenv(dotenv_path=env_path)

upload_dir.mkdir(exist_ok=True)

# FFmpeg ê²½ë¡œ
local_ffmpeg = current_dir / "ffmpeg.exe"
FFMPEG_CMD = str(local_ffmpeg) if local_ffmpeg.exists() else "ffmpeg"

app = FastAPI()

# CORS í•„ìˆ˜!!!
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

GEMINI_MODEL = "gemini-3-pro-preview"  # ìµœì‹  ë²„ì „ìœ¼ë¡œ ê°•ì œ

def format_timestamp(seconds):
    hours = math.floor(seconds / 3600)
    seconds %= 3600
    minutes = math.floor(seconds / 60)
    seconds %= 60
    ms = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{ms:03d}"

# --------------------------------------------------------
# ìë§‰ ë¶„í•  (ê·¸ëŒ€ë¡œ ì˜ ë¨)
# --------------------------------------------------------
def regroup_words_dynamic(words):
    segments = []
    current = {"text": "", "start": 0, "end": 0, "words": []}
    MAX_SILENCE = 0.3
    MAX_CHARS = 35

    for word_obj in words:
        word = word_obj.word
        start = word_obj.start
        end = word_obj.end

        if current["words"]:
            silence = start - current["words"][-1].end
            if silence > MAX_SILENCE:
                current["end"] = current["words"][-1].end
                segments.append(current)
                current = {"text": "", "start": start, "end": 0, "words": []}

        if not current["words"]:
            current["start"] = start
        current["text"] += word
        current["words"].append(word_obj)
        current["end"] = end

        too_long = len(current["text"]) > MAX_CHARS
        sentence_end = word.strip() and word.strip()[-1] in ".?!"

        if too_long or sentence_end:
            segments.append(current)
            current = {"text": "", "start": 0, "end": 0, "words": []}

    if current["words"]:
        segments.append(current)
    return segments

# --------------------------------------------------------
# Gemini ë²ˆì—­ (ì™„ì „ ë°©ì–´í˜•)
# --------------------------------------------------------
def translate_batch_gemini(segments, genre_guide):
    input_data = [{"id": i, "text": seg["text"]} for i, seg in enumerate(segments)]
    
    prompt = f"""
    ë„ˆëŠ” **í•œêµ­ì¸ì´ ê°€ì¥ ìì—°ìŠ¤ëŸ½ê²Œ ë§í•˜ëŠ” ë°©ì‹**ìœ¼ë¡œ ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ìµœê³ ì˜ AI ë²ˆì—­ê°€ì•¼.

    [ì¥ë¥´Â·ìƒí™© ë¶„ì„ ê²°ê³¼]
    {genre_guide}

    [ë²ˆì—­ ì›ì¹™] â€” ì´ê±´ ë¬´ì¡°ê±´ ì§€ì¼œ!
    1. "{genre_guide}"ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•´ì„œ í†¤ì„ ë§ì¶°.
    - ê°•ì˜ë©´ â†’ ì„¤ëª…í•˜ëŠ” ë§íˆ¬, ì¡´ì¹­ ì ì ˆíˆ
    - ë¸Œì´ë¡œê·¸Â·ìœ íŠœë¸Œë©´ â†’ ì™„ì „ ë°˜ë§, ì¹œêµ¬ë‘ ì–˜ê¸°í•˜ë“¯ì´, "ã…‹ã…‹", "ì§„ì§œ", "ì™„ì „" ê°™ì€ ê°íƒ„ì‚¬ë„ OK
    - ì˜í™”Â·ë“œë¼ë§ˆë©´ â†’ ì¸ë¬¼ ì„±ê²©ê³¼ ê°ì • ì‚´ë ¤ì„œ êµ¬ì–´ì²´ ë°˜ë§ or ì¡´ëŒ“ë§
    - ë‹¤íë©´ â†’ ì°¨ë¶„í•˜ê³  ì •í™•í•œ ì„¤ëª…ì²´
    - ê²Œì„ ìŠ¤íŠ¸ë¦¬ë°ì´ë©´ â†’ "ì™€ ì´ê±° ê°œì©ë‹¤", "ë¯¸ì³¤ë„¤" ì´ëŸ° ë§ë„ ì¨

    2. **ë¬¸ì–´ì²´, ì±… ë§íˆ¬ ì™ ë§Œí•´ì„œëŠ” ì“°ì§€ ë§ˆ** â†’ "ì…ë‹ˆë‹¤", "í•©ë‹ˆë‹¤" ê°™ì€ ê±° ê°€ëŠ¥í•œ ë¹¼ê³  ë§í•˜ë“¯ì´ í•´
    3. í•œêµ­ ì‚¬ëŒì´ ì§„ì§œë¡œ ì“°ëŠ” ë„ì–´ì“°ê¸°, ì¤„ì„ë§, êµ¬ì–´ì²´ ì™„ë²½íˆ ì‚´ë ¤ (ì˜ˆ: "ê·¸ë‹ˆê¹Œ" ëŒ€ì‹  "ê·¸ëŸ¬ë‹ˆê¹Œ" X, "ì•„ë‹ˆ" ëŒ€ì‹  "ì•„ë‹ˆì•¼" O)
    4. ê°ì •, ì›ƒìŒ, ë†€ëŒ, í™”ë‚¨ ê°™ì€ ê±´ ê·¸ëŒ€ë¡œ ì‚´ë ¤! (ã…‹ã…‹ã…‹, !!!, ... ë„ ì ê·¹ ì‚¬ìš©)

ë²ˆì—­í•  í…ìŠ¤íŠ¸ (ìˆœì„œ ì ˆëŒ€ ë°”ê¾¸ì§€ ë§ˆ):

    [ê°€ì´ë“œ]
    {genre_guide}

    ë²ˆì—­í•  í…ìŠ¤íŠ¸:
    {json.dumps(input_data, ensure_ascii=False)}

    ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ``` ë¹¼ê³ , ì„¤ëª…ë„ ë¹¼ê³ :
    [{{"id": 0, "ko": "ë²ˆì—­ë¬¸1"}}, {{"id": 1, "ko": "ë²ˆì—­ë¬¸2"}}]
    """

    try:
        model = genai.GenerativeModel(
            model_name=GEMINI_MODEL,
            generation_config={
                "response_mime_type": "application/json",
                "temperature": 0.7
            }
        )
        response = model.generate_content(prompt)
        raw = response.text.strip()

        print(f"[Gemini ì‘ë‹µ] {raw[:500]}")  # ë””ë²„ê·¸ìš©

        # ë§ˆí¬ë‹¤ìš´ ì œê±°
        if "```" in raw:
            raw = re.search(r"```(?:json)?\s*(.*?)\s*```", raw, re.DOTALL)
            raw = raw.group(1) if raw else raw

        data = json.loads(raw)

        # í‚¤ ë³´ì •
        result = []
        for i, item in enumerate(data):
            ko_text = item.get("ko") or item.get("korean") or item.get("text") or "ë²ˆì—­ì—†ìŒ"
            result.append({"id": item.get("id", i), "ko": ko_text})
        return result

    except Exception as e:
        print(f"Gemini ì™„ì „ ì‹¤íŒ¨: {e}")
        return [{"id": d["id"], "ko": d["text"] + " (ë²ˆì—­ì‹¤íŒ¨)"} for d in input_data]

# --------------------------------------------------------
# ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------------
@app.post("/upload/video")
async def upload_video(file: UploadFile = File(..., max_size=10_000_000_000)):
    file_id = str(uuid.uuid4())
    filename = f"{file_id}.mp4"
    file_path = upload_dir / filename
    audio_path = upload_dir / f"{file_id}.mp3"
    srt_path = upload_dir / f"{file_id}.srt"
    output_path = upload_dir / f"subtitled_{file_id}.mp4"

    try:
        # 1. íŒŒì¼ ì €ì¥
        print("íŒŒì¼ ì €ì¥ ì¤‘...")
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")

        # 2. ì˜¤ë””ì˜¤ ì¶”ì¶œ (FFmpeg)
        print("ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
        subprocess.run([
            FFMPEG_CMD, "-y", "-i", str(file_path), 
            "-vn", "-acodec", "libmp3lame", str(audio_path)
        ], check=True, creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0)
        print(f"âœ… ì˜¤ë””ì˜¤ ì¶”ì¶œ ì™„ë£Œ: {audio_path}")

        # 3. Whisper STT
        print("Whisper STT ì‹œì‘...")
        openai_key = os.getenv("OPENAI_API_KEY")
        gemini_key = os.getenv("GEMINI_API_KEY")
        
        if not openai_key:
            raise HTTPException(status_code=500, detail="OPENAI_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤!")
        if not gemini_key:
            raise HTTPException(status_code=500, detail="GEMINI_API_KEYê°€ .envì— ì—†ìŠµë‹ˆë‹¤!")
        
        client = OpenAI(api_key=openai_key)
        genai.configure(api_key=gemini_key)
        
        with open(audio_path, "rb") as af:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=af,
                response_format="verbose_json",
                timestamp_granularities=["word"]
            )
        print(f"âœ… STT ì™„ë£Œ: {len(transcript.words)} ë‹¨ì–´")

        # 4. ìë§‰ ë¶„í• 
        print("ìë§‰ ë¶„í•  ì¤‘...")
        segments = regroup_words_dynamic(transcript.words)
        print(f"âœ… ë¶„í•  ì™„ë£Œ: {len(segments)} ì„¸ê·¸ë¨¼íŠ¸")

        # 5. ì¥ë¥´ ë¶„ì„
        print("ì¥ë¥´ ë¶„ì„ ì¤‘...")
        sample = " ".join([s["text"] for s in segments[:30]])
        guide_model = genai.GenerativeModel(GEMINI_MODEL)
        guide_res = guide_model.generate_content(
    f"""ì•„ë˜ ëŒ€ë³¸ ìƒ˜í”Œ ë³´ê³  ë”± 3ì¤„ë¡œ ìš”ì•½í•´ì¤˜:

    1. ì´ ì˜ìƒì˜ ì¥ë¥´/ì¢…ë¥˜ëŠ”? (ì˜í™”, ìœ íŠœë¸Œ, ê°•ì˜, ë‹¤í, ê²Œì„ ìŠ¤íŠ¸ë¦¬ë°, ASMR, ë¸Œì´ë¡œê·¸ ë“±)
    2. ë§í•˜ëŠ” ì‚¬ëŒì˜ í†¤ì€? (ë°˜ë§/ì¡´ëŒ“ë§, ìºì£¼ì–¼/ì§„ì§€/ê°ì •ì /ì°¨ë¶„/í¥ë¶„ ë“±)
    3. í•œêµ­ì–´ ë²ˆì—­í•  ë•Œ ì–´ë–¤ ë§íˆ¬ë¡œ í•´ì•¼ ì œì¼ ìì—°ìŠ¤ëŸ¬ìš¸ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ

    ëŒ€ë³¸ ìƒ˜í”Œ:
    {sample}

    í˜•ì‹:
    1. [ì¥ë¥´]
    2. [í†¤]
    3. [ì¶”ì²œ ë²ˆì—­ ìŠ¤íƒ€ì¼]"""
    )
        genre_guide = guide_res.text.strip()
        print(f"ğŸ¯ ë¶„ì„ ê²°ê³¼: {genre_guide}")

        # 6. ë²ˆì—­
        print(f"ë²ˆì—­ ì‹œì‘ ({len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸)")
        final_srt = []
        BATCH_SIZE = 100

        for i in range(0, len(segments), BATCH_SIZE):
            chunk = segments[i:i+BATCH_SIZE]
            translated = translate_batch_gemini(chunk, genre_guide)

            # ì•ˆì „ ë§¤í•‘
            trans_map = {}
            for idx, item in enumerate(translated):
                orig_text = chunk[idx]["text"]
                ko_text = item.get("ko", orig_text + " (ì˜¤ë¥˜)")
                trans_map[item.get("id", idx)] = ko_text

            for idx, seg in enumerate(chunk):
                ko = trans_map.get(idx, seg["text"])
                start = format_timestamp(seg["start"])
                end = format_timestamp(seg["end"])
                num = i + idx + 1
                final_srt.append(f"{num}\n{start} --> {end}\n{ko}\n\n")

            print(f" â†’ {min(i+BATCH_SIZE, len(segments))}/{len(segments)} ì™„ë£Œ")

        # 7. SRT ì €ì¥
        with open(srt_path, "w", encoding="utf-8") as f:
            f.write("".join(final_srt))
        print(f"âœ… SRT ì €ì¥ ì™„ë£Œ: {srt_path}")

        # 8. í•˜ë“œì„œë¸Œ (FFmpeg - ì™„ë²½ escaping ë²„ì „)
        print("í•˜ë“œì„œë¸Œ ì‹œì‘...")
        def escape_ffmpeg_path(path):
            s = str(path)
            s = s.replace("\\", "/")  # ìŠ¬ë˜ì‹œë¡œ í†µì¼
            s = s.replace(":", "\\:")  # ë“œë¼ì´ë¸Œ ì½œë¡  escaping
            s = s.replace("'", "'\\''")  # ì‘ì€ë”°ì˜´í‘œ escaping
            return s

        safe_srt_path = escape_ffmpeg_path(srt_path)
        print(f"[DEBUG] FFmpeg SRT ê²½ë¡œ: {safe_srt_path}")

        style = "Fontname=Malgun Gothic,Fontsize=18,PrimaryColour=&H00FFFFFF,OutlineColour=&H00000000,BorderStyle=1,Outline=2,Shadow=1,MarginV=35"

        ffmpeg_cmd = [
            FFMPEG_CMD, "-y",
            "-i", str(file_path),
            "-vf", f"subtitles='{safe_srt_path}':force_style='{style}'",
            "-c:a", "copy",
            str(output_path)
        ]

        print(f"[FFmpeg ëª…ë ¹ì–´]: {' '.join(ffmpeg_cmd)}")

        result = subprocess.run(
            ffmpeg_cmd,
            check=True,
            capture_output=True,
            text=True,
            creationflags=subprocess.CREATE_NO_WINDOW if os.name == "nt" else 0
        )
        print(f"âœ… í•˜ë“œì„œë¸Œ ì™„ë£Œ! FFmpeg ì¶œë ¥: {result.stdout[:200]}...")

        print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼ ì „ì†¡")
        return FileResponse(output_path, media_type="video/mp4", filename="walnut_subtitled.mp4")

    except HTTPException:
        raise  # ì´ë¯¸ HTTPExceptionì´ë©´ ê·¸ëŒ€ë¡œ ë±‰ê¸°
    except Exception as e:
        import traceback
        print(f"âŒ [CRITICAL ERROR] {e}")
        traceback.print_exc()
        # ì„ì‹œ íŒŒì¼ë“¤ ì‚­ì œ (ì •ë¦¬)
        for path in [file_path, audio_path, srt_path, output_path]:
            if path.exists():
                path.unlink()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
    
    # === ìƒˆë¡œìš´ ì—”ë“œí¬ì¸íŠ¸: í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (30 í˜¸ë‘) ===
@app.post("/upload/text")
async def extract_text(file: UploadFile = File(...)):
    file_id = str(uuid.uuid4())
    file_path = upload_dir / f"{file_id}_audio"
    
    # ì§€ì› í™•ì¥ì (mp4, mp3, wav, m4a ë“±)
    allowed = ["mp4", "mp3", "wav", "m4a", "webm", "ogg"]
    ext = file.filename.lower().split(".")[-1]
    if ext not in allowed:
        raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    try:
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)

        print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘... (Whisper ìë™ ì–¸ì–´ ê°ì§€)")

        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        with open(file_path, "rb") as af:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=af,
                response_format="verbose_json",           # â† ì´ê±° ìˆìœ¼ë©´ ì–¸ì–´ ê°ì§€ + ì„¸ê·¸ë¨¼íŠ¸ ì¤Œ
                timestamp_granularities=["word"]          # â† ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ (í•„ìˆ˜ëŠ” ì•„ë‹˜)
            )

        # ì–¸ì–´ ê°ì§€ ê²°ê³¼ (Whisperê°€ ìë™ìœ¼ë¡œ ì•Œë ¤ì¤Œ!)
        detected_lang = transcript.language
        full_text = transcript.text.strip()

        print(f"ê°ì§€ëœ ì–¸ì–´: {detected_lang.upper()}")
        print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}ì")

        # ê²°ê³¼ JSONìœ¼ë¡œ ë±‰ê¸° (í”„ë¡ íŠ¸ì—ì„œ ë°”ë¡œ ë³´ì—¬ì¤„ ìˆ˜ ìˆê²Œ)
        result = {
            "language": detected_lang,
            "text": full_text,
            "segments": [
                {
                    "start": seg.start,
                    "end": seg.end,
                    "text": seg.text
                } for seg in transcript.segments
            ] if hasattr(transcript, "segments") else []
        }

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if file_path.exists():
            file_path.unlink()

        return result

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")